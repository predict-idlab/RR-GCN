{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc4438b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:54:10.300420Z",
     "iopub.status.busy": "2022-02-17T15:54:10.298229Z",
     "iopub.status.idle": "2022-02-17T15:54:17.948572Z",
     "shell.execute_reply": "2022-02-17T15:54:17.949054Z"
    },
    "papermill": {
     "duration": 7.698719,
     "end_time": "2022-02-17T15:54:17.950043",
     "exception": false,
     "start_time": "2022-02-17T15:54:10.251324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from torch_geometric.nn import GAE\n",
    "from torch_geometric.datasets import RelLinkPredDataset\n",
    "from rrgcn import RRGCNEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ec49f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:54:18.036210Z",
     "iopub.status.busy": "2022-02-17T15:54:18.034941Z",
     "iopub.status.idle": "2022-02-17T15:54:18.090288Z",
     "shell.execute_reply": "2022-02-17T15:54:18.090822Z"
    },
    "papermill": {
     "duration": 0.112811,
     "end_time": "2022-02-17T15:54:18.091012",
     "exception": false,
     "start_time": "2022-02-17T15:54:17.978201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = RelLinkPredDataset('/project_scratch/rrgcn_datasets/RLPD', 'FB15k-237')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0727392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:54:18.630056Z",
     "iopub.status.busy": "2022-02-17T15:54:18.628907Z",
     "iopub.status.idle": "2022-02-17T15:54:18.639367Z",
     "shell.execute_reply": "2022-02-17T15:54:18.639979Z"
    },
    "papermill": {
     "duration": 0.111408,
     "end_time": "2022-02-17T15:54:18.640212",
     "exception": false,
     "start_time": "2022-02-17T15:54:18.528804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/pyg-team/pytorch_geometric/blob/master/examples/rgcn_link_pred.py\n",
    "class DistMultDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_dim, num_relations, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.pre_lin = torch.nn.Linear(in_dim, hidden_channels)\n",
    "        self.lin = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.rel_emb = Parameter(torch.Tensor(num_relations, hidden_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.rel_emb)\n",
    "\n",
    "    def forward(self, z, edge_index, edge_type):\n",
    "        z = F.relu(self.pre_lin(z))\n",
    "        z = F.relu(self.lin(z))\n",
    "        z = F.relu(self.lin1(z))\n",
    "        z = F.relu(self.lin2(z))\n",
    "        z_src, z_dst = z[edge_index[0]], z[edge_index[1]]\n",
    "        rel = self.rel_emb[edge_type]\n",
    "        return torch.sum(z_src * rel * z_dst, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5efba59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:54:19.007969Z",
     "iopub.status.busy": "2022-02-17T15:54:18.991112Z",
     "iopub.status.idle": "2022-02-17T17:03:25.145275Z",
     "shell.execute_reply": "2022-02-17T17:03:25.145825Z"
    },
    "papermill": {
     "duration": 4146.173915,
     "end_time": "2022-02-17T17:03:25.146129",
     "exception": false,
     "start_time": "2022-02-17T15:54:18.972214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5259/1212483593.py:209: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(z).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00100, Loss: 0.1382\n",
      "Epoch: 00200, Loss: 0.1086\n",
      "Epoch: 00300, Loss: 0.0872\n",
      "Epoch: 00400, Loss: 0.0863\n",
      "Epoch: 00500, Loss: 0.0717\n",
      "Epoch: 00600, Loss: 0.0661\n",
      "Epoch: 00700, Loss: 0.0642\n",
      "Epoch: 00800, Loss: 0.0611\n",
      "Epoch: 00900, Loss: 0.0576\n",
      "Epoch: 01000, Loss: 0.0528\n",
      "Epoch: 01100, Loss: 0.0563\n",
      "Epoch: 01200, Loss: 0.0547\n",
      "Epoch: 01300, Loss: 0.0536\n",
      "Epoch: 01400, Loss: 0.0470\n",
      "Epoch: 01500, Loss: 0.0449\n",
      "Epoch: 01600, Loss: 0.0494\n",
      "Epoch: 01700, Loss: 0.0470\n",
      "Epoch: 01800, Loss: 0.0424\n",
      "Epoch: 01900, Loss: 0.0414\n",
      "Epoch: 02000, Loss: 0.0396\n",
      "Epoch: 02100, Loss: 0.0452\n",
      "Epoch: 02200, Loss: 0.0510\n",
      "Epoch: 02300, Loss: 0.0491\n",
      "Epoch: 02400, Loss: 0.0363\n",
      "Epoch: 02500, Loss: 0.0364\n",
      "Epoch: 02600, Loss: 0.0440\n",
      "Epoch: 02700, Loss: 0.0423\n",
      "Epoch: 02800, Loss: 0.0369\n",
      "Epoch: 02900, Loss: 0.0394\n",
      "Epoch: 03000, Loss: 0.0481\n",
      "Epoch: 03100, Loss: 0.0378\n",
      "Epoch: 03200, Loss: 0.0323\n",
      "Epoch: 03300, Loss: 0.0337\n",
      "Epoch: 03400, Loss: 0.0330\n",
      "Epoch: 03500, Loss: 0.0331\n",
      "Epoch: 03600, Loss: 0.0308\n",
      "Epoch: 03700, Loss: 0.0319\n",
      "Epoch: 03800, Loss: 0.0337\n",
      "Epoch: 03900, Loss: 0.0312\n",
      "Epoch: 04000, Loss: 0.0309\n",
      "Epoch: 04100, Loss: 0.0345\n",
      "Epoch: 04200, Loss: 0.0394\n",
      "Epoch: 04300, Loss: 0.0304\n",
      "Epoch: 04400, Loss: 0.0290\n",
      "Epoch: 04500, Loss: 0.0293\n",
      "Epoch: 04600, Loss: 0.0289\n",
      "Epoch: 04700, Loss: 0.0287\n",
      "Epoch: 04800, Loss: 0.0291\n",
      "Epoch: 04900, Loss: 0.0283\n",
      "Epoch: 05000, Loss: 0.0297\n",
      "Epoch: 05100, Loss: 0.0311\n",
      "Epoch: 05200, Loss: 0.0278\n",
      "Epoch: 05300, Loss: 0.0290\n",
      "Epoch: 05400, Loss: 0.0276\n",
      "Epoch: 05500, Loss: 0.0282\n",
      "Epoch: 05600, Loss: 0.0290\n",
      "Epoch: 05700, Loss: 0.0274\n",
      "Epoch: 05800, Loss: 0.0277\n",
      "Epoch: 05900, Loss: 0.0269\n",
      "Epoch: 06000, Loss: 0.0266\n",
      "Epoch: 06100, Loss: 0.0272\n",
      "Epoch: 06200, Loss: 0.0271\n",
      "Epoch: 06300, Loss: 0.0267\n",
      "Epoch: 06400, Loss: 0.0261\n",
      "Epoch: 06500, Loss: 0.0304\n",
      "Epoch: 06600, Loss: 0.0374\n",
      "Epoch: 06700, Loss: 0.0264\n",
      "Epoch: 06800, Loss: 0.0270\n",
      "Epoch: 06900, Loss: 0.0251\n",
      "Epoch: 07000, Loss: 0.0267\n",
      "Epoch: 07100, Loss: 0.0261\n",
      "Epoch: 07200, Loss: 0.0263\n",
      "Epoch: 07300, Loss: 0.0262\n",
      "Epoch: 07400, Loss: 0.0262\n",
      "Epoch: 07500, Loss: 0.0265\n",
      "Epoch: 07600, Loss: 0.0258\n",
      "Epoch: 07700, Loss: 0.0302\n",
      "Epoch: 07800, Loss: 0.0255\n",
      "Epoch: 07900, Loss: 0.0250\n",
      "Epoch: 08000, Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5259/1212483593.py:153: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  branks = raw_ranks + (num_ties - 1) // 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23814451162854694\n",
      "(0.15665005374767907, 0.2563764291996482, 0.4116339294439558)\n"
     ]
    }
   ],
   "source": [
    "rrgcn_dim = 32000\n",
    "pca_dim = 8192\n",
    "num_layers = 2\n",
    "lr = 0.0001\n",
    "h = 2048\n",
    "\n",
    "model = GAE(\n",
    "    RRGCNEmbedder(\n",
    "        data.num_nodes,\n",
    "        num_layers,\n",
    "        dataset.num_relations,\n",
    "        rrgcn_dim,\n",
    "        device=\"cuda\",\n",
    "        seed=42,\n",
    "    ),\n",
    "    DistMultDecoder(pca_dim, dataset.num_relations // 2, hidden_channels=h),\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def negative_sampling(edge_index, num_nodes):\n",
    "    # Sample edges by corrupting either the subject or the object of each edge.\n",
    "    mask_1 = torch.rand(edge_index.size(1)) < 0.5\n",
    "    mask_2 = ~mask_1\n",
    "\n",
    "    neg_edge_index = edge_index.clone()\n",
    "    neg_edge_index[0, mask_1.to(edge_index.device)] = torch.randint(\n",
    "        num_nodes, (mask_1.sum(),)\n",
    "    ).to(edge_index.device)\n",
    "    neg_edge_index[1, mask_2.to(edge_index.device)] = torch.randint(\n",
    "        num_nodes, (mask_2.sum(),)\n",
    "    ).to(edge_index.device)\n",
    "    return neg_edge_index\n",
    "\n",
    "\n",
    "def train(z):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pos_out = model.decode(z, data.train_edge_index, data.train_edge_type)\n",
    "\n",
    "    neg_edge_index = negative_sampling(data.train_edge_index, data.num_nodes)\n",
    "    neg_out = model.decode(z, neg_edge_index, data.train_edge_type)\n",
    "\n",
    "    out = torch.cat([pos_out, neg_out])\n",
    "\n",
    "    gt = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
    "    loss = F.binary_cross_entropy_with_logits(out, gt)\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def filter_scores(scores, batch, true_triples, head=True):\n",
    "    \"\"\" Filters a score matrix by setting the scores of known non-target true triples to -infinity \"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    indices = []  # indices of triples whose scores should be set to -infinity\n",
    "\n",
    "    heads, tails = true_triples\n",
    "\n",
    "    for i, (s, p, o) in enumerate(batch):\n",
    "        s, p, o = (s.item(), p.item(), o.item())\n",
    "        if head:\n",
    "            indices.extend([(i, si) for si in heads[p, o] if si != s])\n",
    "        else:\n",
    "            indices.extend([(i, oi) for oi in tails[s, p] if oi != o])\n",
    "        # -- We add the indices of all know triples except the one corresponding to the target triples.\n",
    "\n",
    "    indices = torch.tensor(indices, device=device)\n",
    "\n",
    "    scores[indices[:, 0], indices[:, 1]] = float(\"-inf\")\n",
    "\n",
    "\n",
    "# score calculation code adapted from\n",
    "# https://github.com/thiviyanT/torch-rgcn\n",
    "# instead of torch_geometric (100x speedup)\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model,\n",
    "    z,\n",
    "    test_edge_index,\n",
    "    test_edge_type,\n",
    "    true_triples,\n",
    "    num_nodes,\n",
    "    batch_size=16,\n",
    "    hits_at_k=[1, 3, 10],\n",
    "    filter_candidates=True,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\" Evaluates a triple scoring model. Does the sorting in a single, GPU-accelerated operation. \"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    rng = tqdm.trange if verbose else range\n",
    "\n",
    "    ranks = []\n",
    "    for head in [True, False]:  # head or tail prediction\n",
    "\n",
    "        for fr in rng(0, test_edge_type.numel(), batch_size):\n",
    "            to = min(fr + batch_size, test_edge_type.numel())\n",
    "\n",
    "            batch = (\n",
    "                torch.vstack(\n",
    "                    (\n",
    "                        test_edge_index[0, fr:to],\n",
    "                        test_edge_type[fr:to],\n",
    "                        test_edge_index[1, fr:to],\n",
    "                    )\n",
    "                )\n",
    "                .to(device=device)\n",
    "                .T\n",
    "            )\n",
    "            bn, _ = batch.size()\n",
    "\n",
    "            # compute the full score matrix (filter later)\n",
    "            bases = batch[:, 1:] if head else batch[:, :2]\n",
    "            targets = batch[:, 0] if head else batch[:, 2]\n",
    "\n",
    "            # collect the triples for which to compute scores\n",
    "            bexp = bases.view(bn, 1, 2).expand(bn, num_nodes, 2)\n",
    "            ar = (\n",
    "                torch.arange(num_nodes, device=device)\n",
    "                .view(1, num_nodes, 1)\n",
    "                .expand(bn, num_nodes, 1)\n",
    "            )\n",
    "            toscore = torch.cat([ar, bexp] if head else [bexp, ar], dim=2)\n",
    "            assert toscore.size() == (bn, num_nodes, 3)\n",
    "            toscore = toscore.reshape((bn * num_nodes, 3))\n",
    "            to_score_edge_index = torch.vstack((toscore[:, 0], toscore[:, 2]))\n",
    "            to_score_edge_type = toscore[:, 1]\n",
    "            scores = model.decode(z, to_score_edge_index, to_score_edge_type)\n",
    "            scores = scores.reshape((bn, num_nodes))\n",
    "\n",
    "            # filter out the true triples that aren't the target\n",
    "            if filter_candidates:\n",
    "                filter_scores(scores, batch.cpu(), true_triples, head=head)\n",
    "\n",
    "            # Select the true scores, and count the number of values larger than than\n",
    "            true_scores = scores[torch.arange(bn, device=device), targets]\n",
    "            raw_ranks = torch.sum(\n",
    "                scores > true_scores.view(bn, 1), dim=1, dtype=torch.long\n",
    "            )\n",
    "            # -- This is the \"optimistic\" rank (assuming it's sorted to the front of the ties)\n",
    "            num_ties = torch.sum(\n",
    "                scores == true_scores.view(bn, 1), dim=1, dtype=torch.long\n",
    "            )\n",
    "\n",
    "            # Account for ties (put the true example halfway down the ties)\n",
    "            branks = raw_ranks + (num_ties - 1) // 2\n",
    "\n",
    "            ranks.extend((branks + 1).tolist())\n",
    "\n",
    "    mrr = sum([1.0 / rank for rank in ranks]) / len(ranks)\n",
    "\n",
    "    hits = []\n",
    "    for k in hits_at_k:\n",
    "        hits.append(sum([1.0 if rank <= k else 0.0 for rank in ranks]) / len(ranks))\n",
    "\n",
    "    return mrr, tuple(hits)  # , ranks\n",
    "\n",
    "\n",
    "def generate_true_dict(all_triples):\n",
    "    \"\"\" Generates a pair of dictionaries containing all true tail and head completions \"\"\"\n",
    "    heads, tails = (\n",
    "        {(p, o): [] for _, p, o in all_triples},\n",
    "        {(s, p): [] for s, p, _ in all_triples},\n",
    "    )\n",
    "\n",
    "    for s, p, o in all_triples:\n",
    "        heads[p, o].append(s)\n",
    "        tails[s, p].append(o)\n",
    "\n",
    "    return heads, tails\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "data = data.to(device)\n",
    "model.to(device)\n",
    "\n",
    "z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "m = z.mean(0, keepdim=True)\n",
    "s = z.std(0, unbiased=False, keepdim=True)\n",
    "z -= m\n",
    "z /= s\n",
    "\n",
    "U, S, V = torch.pca_lowrank(z, pca_dim)\n",
    "z = torch.matmul(z, V[:, :pca_dim])\n",
    "\n",
    "train_batch = torch.vstack(\n",
    "    (data.train_edge_index[0, :], data.train_edge_type, data.train_edge_index[1, :])\n",
    ").T\n",
    "valid_batch = torch.vstack(\n",
    "    (data.valid_edge_index[0, :], data.valid_edge_type, data.valid_edge_index[1, :])\n",
    ").T\n",
    "test_batch = torch.vstack(\n",
    "    (data.test_edge_index[0, :], data.test_edge_type, data.test_edge_index[1, :])\n",
    ").T\n",
    "\n",
    "true_triples = generate_true_dict(\n",
    "    torch.vstack((train_batch, valid_batch, test_batch)).cpu().numpy()\n",
    ")\n",
    "\n",
    "z = torch.tensor(z).to(device)\n",
    "\n",
    "mrr = 0\n",
    "for epoch in range(1, 8001):\n",
    "    loss = train(z)\n",
    "    if (epoch % 100) == 0:\n",
    "        print(f\"Epoch: {epoch:05d}, Loss: {loss:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "mrr, hits = evaluate(\n",
    "    model,\n",
    "    z,\n",
    "    data.test_edge_index,\n",
    "    data.test_edge_type,\n",
    "    true_triples,\n",
    "    data.num_nodes,\n",
    "    batch_size=25,\n",
    "    verbose=False,\n",
    ")\n",
    "print(mrr)\n",
    "print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d45497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23814451162854694\n",
      "(0.15665005374767907, 0.2563764291996482, 0.4116339294439558)\n"
     ]
    }
   ],
   "source": [
    "print(mrr)\n",
    "print(hits)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4168.082368,
   "end_time": "2022-02-17T17:03:36.355197",
   "environment_variables": {},
   "exception": null,
   "input_path": "fast_link_pred_pca.ipynb",
   "output_path": "lp_pca_results.ipynb",
   "parameters": {},
   "start_time": "2022-02-17T15:54:08.272829",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
